{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voynich.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSw7umh-QL9h"
      },
      "source": [
        "# Setup Work Environment\n",
        "\n",
        "Run the following cell to setup all the dependencies and the code. There should be no changes required from this cell.\n",
        "\n",
        "Don't forget to ensure the GPU has already attached to your working environment. You can check it in `Runtime -> Manage sessions -> Check if word GPU is available next to the notebook's name`, you can also double check in `Runtime -> Change runtime type -> Check if GPU has already selected from the dropdown menu`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XmdHh775Jsh",
        "outputId": "6519e945-2f28-44fd-aa1c-8838c72ae5bc"
      },
      "source": [
        "!rm -rf xib\n",
        "!pip install pytrie enlighten colorlog inflection ipapy\n",
        "!git clone https://github.com/akurniawan/xib.git\n",
        "!cd xib && git clone https://github.com/j-luo93/dev_misc.git && cd dev_misc && git checkout b44fde842a6311e03f731cd4e110dcd9fc394db7 && pip install -e .\n",
        "!cd xib && pip install -e ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytrie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/19/15ec77ab9c85f7c36eb590d6ab7dd529f8c8516c0e2219f1a77a99d7ee77/PyTrie-0.4.0.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 5.8MB/s \n",
            "\u001b[?25hCollecting enlighten\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/15/7a22630323eb816bd560bb2b60b98c9c829a3fb90f55d9d224f3aa4d7bf3/enlighten-1.10.1-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.0MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Collecting inflection\n",
            "  Downloading https://files.pythonhosted.org/packages/59/91/aa6bde563e0085a02a435aa99b49ef75b0a4b062635e606dab23ce18d720/inflection-0.5.1-py2.py3-none-any.whl\n",
            "Collecting ipapy\n",
            "  Downloading https://files.pythonhosted.org/packages/41/0d/7e8652df6af20a61bb3315f5c9d99fb9ea8f3779ff80fca9d71001230f90/ipapy-0.0.9.0.tar.gz\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pytrie) (2.4.0)\n",
            "Collecting prefixed>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/54/70/5356a73361214257618f2ff07afb539a44f4519db4c3112b981f910e02a1/prefixed-0.3.2-py2.py3-none-any.whl\n",
            "Collecting blessed>=1.17.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/35/a781470488a304f66843d328052b6cb22df7163246fb47a27bfb21fba4e6/blessed-1.18.0-py2.py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.7->enlighten) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.7->enlighten) (1.15.0)\n",
            "Building wheels for collected packages: pytrie, ipapy\n",
            "  Building wheel for pytrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrie: filename=PyTrie-0.4.0-cp37-none-any.whl size=6089 sha256=4903b4ffa3a3ec9e56732883a5385d3d9b3f8a90bde2e290435ea15439824553\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/2a/41/5870cad27097f3b3d7b3d96aa5897d502db08cafba9051bd62\n",
            "  Building wheel for ipapy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipapy: filename=ipapy-0.0.9.0-cp37-none-any.whl size=38724 sha256=55cbe8d6f98421ec5ac10f9d7b4275416bbf8a775f882be9a12c2ed1b999ccc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/f3/00/9f83f4dada00246acda572d4248dc8215c5a8ca37bb4f173a8\n",
            "Successfully built pytrie ipapy\n",
            "Installing collected packages: pytrie, prefixed, blessed, enlighten, colorlog, inflection, ipapy\n",
            "Successfully installed blessed-1.18.0 colorlog-5.0.1 enlighten-1.10.1 inflection-0.5.1 ipapy-0.0.9.0 prefixed-0.3.2 pytrie-0.4.0\n",
            "Cloning into 'xib'...\n",
            "remote: Enumerating objects: 3093, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 3093 (delta 32), reused 47 (delta 24), pack-reused 3032\u001b[K\n",
            "Receiving objects: 100% (3093/3093), 636.08 KiB | 5.83 MiB/s, done.\n",
            "Resolving deltas: 100% (2434/2434), done.\n",
            "Cloning into 'dev_misc'...\n",
            "remote: Enumerating objects: 2004, done.\u001b[K\n",
            "remote: Counting objects: 100% (437/437), done.\u001b[K\n",
            "remote: Compressing objects: 100% (241/241), done.\u001b[K\n",
            "remote: Total 2004 (delta 311), reused 312 (delta 196), pack-reused 1567\u001b[K\n",
            "Receiving objects: 100% (2004/2004), 344.09 KiB | 13.23 MiB/s, done.\n",
            "Resolving deltas: 100% (1395/1395), done.\n",
            "Note: checking out 'b44fde842a6311e03f731cd4e110dcd9fc394db7'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at b44fde8 py.typed; add_condition for arglib\n",
            "Obtaining file:///content/xib/dev_misc\n",
            "Installing collected packages: dev-misc\n",
            "  Running setup.py develop for dev-misc\n",
            "Successfully installed dev-misc\n",
            "Obtaining file:///content/xib\n",
            "Installing collected packages: xib\n",
            "  Running setup.py develop for xib\n",
            "Successfully installed xib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOvomLGWQdA1"
      },
      "source": [
        "# Setup Dataset\n",
        "\n",
        "There are 2 ways to setup your dataset:\n",
        "1. Mount Gdrive to Colab environment. If you decided to go with this and would like to access the data directly in our `LCT Project` shared folder, you can follow instruction in https://stackoverflow.com/questions/54351852/accessing-shared-with-me-with-colab to load `Preprocessed file` folder in Shared google drive. Essentially you just have to go to the location of the folder, right click and choose `Add a shortcut to Drive`. After that you just have to run the cell below\n",
        "2. Upload your dataset to `sample_data` folder in google colab environment. Be aware that you **will** lose your data in this folder when you restart colab's environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTPLvdDVSfq2",
        "outputId": "652ffcd0-3abf-442f-f575-1e776c850906"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54OeAkgGUazy"
      },
      "source": [
        "# Set your dataset path here\n",
        "KNOWN_LANG_PATH = \"/content/sample_data/it_testing.txt\"\n",
        "UNKNOWN_LANG_PATH = \"/content/sample_data/it_testing.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIUTbLWGS04a"
      },
      "source": [
        "# Run Training\n",
        "\n",
        "As of now, the training will run indefinitely and not sure if changing this will affect the rest of the code. For that reason, we need to stop the training manually once we feel that the losses are no longer improving. We can monitor the `ll` variable from script output inside a table with the following format\n",
        "\n",
        "```\n",
        "+----------------------------------------+  \n",
        "|                  3_8                   |  \n",
        "+-----------+----------+--------+--------+  \n",
        "| name      | value    | weight | mean   |  \n",
        "+-----------+----------+--------+--------+  \n",
        "| grad_norm | 58.492   | 60     | 0.975  |  \n",
        "| ll        | -336.246 | 60     | -5.604 |  \n",
        "| reg       | 0.555    | 60     | 0.009  |  \n",
        "+-----------+----------+--------+--------+\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_MjVoIlX1Gf"
      },
      "source": [
        "# Total number of phonetic feature groups\n",
        "NUM_FEATURE_GROUPS = 10\n",
        "\n",
        "# Total number of phonetic features\n",
        "NUM_FEATURES = 10\n",
        "\n",
        "# Initial value of threshold to determine whether two words are matched. This will determine\n",
        "# whether two words are in match. The bigger the value, the more false positive we will have.\n",
        "# However, if the value is too low, the model will not output anything\n",
        "THRESHOLD = 1.5\n",
        "\n",
        "# Cost in doing insertion and deletion operation in edit distance algorithm, refer to the paper for more details\n",
        "INS_DEL_COST = 100.0\n",
        "\n",
        "# Learning rate for adam optimizer\n",
        "LR = 0.002\n",
        "\n",
        "# How many training steps to do before running the evaluation steps\n",
        "EVAL_INTERVAL = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLKgxArhd80V",
        "outputId": "85e57d4a-df06-4448-9056-9e120a84a859"
      },
      "source": [
        "!PYTHONPATH=/content/xib && /usr/local/bin/python -m xib.main --task extract \\\n",
        "  --vocab_path {KNOWN_LANG_PATH} --data_path {UNKNOWN_LANG_PATH} \\\n",
        "  --dim 112 --min_word_length 1 --max_word_length 10 --input_format text \\\n",
        "  --dense_input --eval_interval 20 \\\n",
        "  --char_per_batch 128 --gpus 0 \\\n",
        "  --num_feature_groups {NUM_FEATURE_GROUPS} --num_features {NUM_FEATURES} \\\n",
        "  --init_threshold {THRESHOLD} --init_ins_del_cost {INS_DEL_COST} --learning_rate {LR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/content/xib/dev_misc/dev_misc/utils.py:36: DeprecationWarning: Class/function Trainer deprecated.\n",
            "  warnings.warn(message, warning_cls)\n",
            "/content/xib/dev_misc/dev_misc/utils.py:36: RuntimeWarning: Class/function DecipherEsNoisyItalianP5Test is buggy.\n",
            "  warnings.warn(message, warning_cls)\n",
            "/usr/local/lib/python3.7/dist-packages/ipapy/ipastring.py:10: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import MutableSequence\n",
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n",
            "\u001b[32mINFO - 05/29/21 09:15:25 - 0:00:00 at parser.py:152 - xib.ipa.process:\n",
            "                                                      \tmin_word_length: 1\n",
            "                                                      xib.data_loader.BaseIpaDataLoader:\n",
            "                                                      \tchar_per_batch: 128\n",
            "                                                      \tdata_path: /content/sample_data/it_testing.txt\n",
            "                                                      \tnew_style: False\n",
            "                                                      \tnum_workers: 0\n",
            "                                                      xib.data_loader:\n",
            "                                                      \tbroken_words: False\n",
            "                                                      \tinput_format: text\n",
            "                                                      \tmax_segment_length: 10\n",
            "                                                      xib.model:\n",
            "                                                      \tdim: 112\n",
            "                                                      \thidden_size: 5\n",
            "                                                      \tnum_feature_groups: 10\n",
            "                                                      \tnum_features: 10\n",
            "                                                      xib.model.modules.Encoder:\n",
            "                                                      \tdense_input: True\n",
            "                                                      \twindow_size: 3\n",
            "                                                      xib.search.searcher.BeamSearcher:\n",
            "                                                      \tbeam_size: 200\n",
            "                                                      xib.model.lm_model.LM:\n",
            "                                                      \tuse_cbow_encoder: True\n",
            "                                                      \tweighted_loss: \n",
            "                                                      xib.model.lm_model.AdaptLM:\n",
            "                                                      \tprior_value: 0.5\n",
            "                                                      \tuse_moe: False\n",
            "                                                      \tuse_prior: False\n",
            "                                                      xib.model.decipher_model.DecipherModel:\n",
            "                                                      \tadapt_mode: none\n",
            "                                                      \tdropout: 0.0\n",
            "                                                      \tlm_model_path: None\n",
            "                                                      \tn_times: 5\n",
            "                                                      \tnum_heads: 4\n",
            "                                                      \tnum_samples: 100\n",
            "                                                      \tnum_self_attn_layers: 2\n",
            "                                                      \tsampling_temperature: 1.0\n",
            "                                                      \tuse_brute_force: False\n",
            "                                                      \tvocab_path: /content/sample_data/it_testing.txt\n",
            "                                                      xib.model.extract_model.G2PLayer:\n",
            "                                                      \tg2p_window_size: 3\n",
            "                                                      xib.model.extract_model.ExtractModel:\n",
            "                                                      \tcontext_weight: 0.0\n",
            "                                                      \tdebug: False\n",
            "                                                      \tinit_ins_del_cost: 100.0\n",
            "                                                      \tinit_threshold: 1.5\n",
            "                                                      \tmax_num_words: 3\n",
            "                                                      \tmax_word_length: 10\n",
            "                                                      \tmin_ins_del_cost: 3.5\n",
            "                                                      \tunextracted_prob: 0.01\n",
            "                                                      \tuse_adapt: False\n",
            "                                                      xib.training.evaluator.DecipherEvaluator:\n",
            "                                                      \teval_max_num_samples: 0\n",
            "                                                      xib.training.evaluator.ExtractEvaluator:\n",
            "                                                      \tmatched_threshold: 0.99\n",
            "                                                      xib.training.trainer.BaseTrainer:\n",
            "                                                      \tcheck_interval: 2\n",
            "                                                      \teval_interval: 20\n",
            "                                                      \tlearning_rate: 0.002\n",
            "                                                      \tnum_steps: 10\n",
            "                                                      \tsave_interval: 0\n",
            "                                                      xib.training.trainer.LMTrainer:\n",
            "                                                      \tfeat_groups: pcvdst\n",
            "                                                      xib.training.trainer.DecipherTrainer:\n",
            "                                                      \tconcentration: 0.01\n",
            "                                                      \tmlm_coeff: 0.05\n",
            "                                                      \tscore_per_word: 1.0\n",
            "                                                      \tsupervised: False\n",
            "                                                      \twarmup_updates: 4000\n",
            "                                                      xib.training.trainer:\n",
            "                                                      \taccum_gradients: 1\n",
            "                                                      xib.training.trainer.ExtractTrainer:\n",
            "                                                      \treg_hyper: 1.0\n",
            "                                                      \tsave_alignment: False\n",
            "                                                      xib.training.manager:\n",
            "                                                      \ttask: extract\n",
            "                                                      xib.training.manager.DecipherManager:\n",
            "                                                      \taux_train_data_path: None\n",
            "                                                      \tdev_data_path: None\n",
            "                                                      \tfix_phi: False\n",
            "                                                      \tin_domain_dev_data_path: None\n",
            "                                                      \tsaved_model_path: None\n",
            "                                                      \tsaved_path: None\n",
            "                                                      \ttrain_phi: False\n",
            "                                                      xib.training.manager.ExtractManager:\n",
            "                                                      \tanneal_factor: 0.5\n",
            "                                                      \tmin_threshold: 0.01\n",
            "                                                      \toptim_cls: adam\n",
            "                                                      __main__:\n",
            "                                                      \tcfg: None\n",
            "                                                      \tgpus: (0,)\n",
            "                                                      \tlog_dir: log/2021-05-29/default/09-15-25\n",
            "                                                      \tlog_level: INFO\n",
            "                                                      \tmessage: \n",
            "                                                      \trandom_seed: 1234\u001b[0m\n",
            "\u001b[32mINFO - 05/29/21 09:15:26 - 0:00:01 at data_loader.py:47 - Loaded 10740 segments in total from /content/sample_data/it_testing.txt.unbroken.text.cache.\u001b[0m\n",
            "\u001b[32mINFO - 05/29/21 09:15:26 - 0:00:01 at data_loader.py:133 - Partitioning the data into batches.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/tensor.py:758: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:934.)\n",
            "  return super(Tensor, self).refine_names(names)\n",
            "\u001b[36mIMP - 05/29/21 09:15:35 - 0:00:11 at logger.py:65 - Unit aligner initialized to 0.\u001b[0m\n",
            "\u001b[1;1H\n",
            "\u001b[K\u001b[1;1H\u001b[1;1H\n",
            "\u001b[K\u001b[1;1H\u001b[1;1H\n",
            "\u001b[K\u001b[1;1H\u001b[1;1H\n",
            "\u001b[K\u001b[1;1H\u001b[1;1H\n",
            "\u001b[Ksave   0%||  0/20 [00:00<?, 0.00/s]\u001b[1;1H\u001b[1;1H\u001b[36mIMP - 05/29/21 09:15:35 - 0:00:11 at logger.py:65 - Setting ins_del_cost to 100.0.\u001b[0m\n",
            "\u001b[36mIMP - 05/29/21 09:15:35 - 0:00:11 at logger.py:65 - Setting threshold to 1.5.\u001b[0m\n",
            "\u001b[32mINFO - 05/29/21 09:15:35 - 0:00:11 at base_trainer.py:87 - Found 41362 trainable parameters.\u001b[0m\n",
            "\u001b[36mIMP - 05/29/21 09:15:36 - 0:00:12 at logger.py:65 - Model saved to log/2021-05-29/default/09-15-25/saved.init.\u001b[0m\n",
            "\u001b[Ktotal_step   0%||  0/10 [00:00<?, 0.00/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:36 - 0:00:12 at base_trainer.py:87 - Found 41362 trainable parameters.\u001b[0m\n",
            "\u001b[K\u001b[1;1H\u001b[1;1H\n",
            "\u001b[Kcheck 100%|| 2/2 [00:02<00:00, 1.18/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:37 - 0:00:12 at base_trainer.py:137 - +-----------------------------------------+\n",
            "                                                            |                   0_2                   |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | name      | value    | weight | mean    |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | grad_norm | 251.066  | 28     | 8.967   |\n",
            "                                                            | ll        | -626.055 | 28     | -22.359 |\n",
            "                                                            | reg       | 0.127    | 28     | 0.005   |\n",
            "                                                            +-----------+----------+--------+---------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 8.39/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:38 - 0:00:13 at base_trainer.py:137 - +-----------------------------------------+\n",
            "                                                            |                   0_4                   |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | name      | value    | weight | mean    |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | grad_norm | 196.944  | 43     | 4.58    |\n",
            "                                                            | ll        | -507.256 | 43     | -11.797 |\n",
            "                                                            | reg       | 0.953    | 43     | 0.022   |\n",
            "                                                            +-----------+----------+--------+---------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.81/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:38 - 0:00:13 at base_trainer.py:137 - +-----------------------------------------+\n",
            "                                                            |                   0_6                   |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | name      | value    | weight | mean    |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | grad_norm | 183.805  | 36     | 5.106   |\n",
            "                                                            | ll        | -548.851 | 36     | -15.246 |\n",
            "                                                            | reg       | 1.462    | 36     | 0.041   |\n",
            "                                                            +-----------+----------+--------+---------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 7.53/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:39 - 0:00:14 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  0_8                   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | name      | value    | weight | mean   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | grad_norm | 227.803  | 46     | 4.952  |\n",
            "                                                            | ll        | -469.671 | 46     | -10.21 |\n",
            "                                                            | reg       | 1.067    | 46     | 0.023  |\n",
            "                                                            +-----------+----------+--------+--------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 7.56/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:39 - 0:00:14 at base_trainer.py:137 - +-----------------------------------------+\n",
            "                                                            |                   0_10                  |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | name      | value    | weight | mean    |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | grad_norm | 274.942  | 39     | 7.05    |\n",
            "                                                            | ll        | -507.323 | 39     | -13.008 |\n",
            "                                                            | reg       | 0.564    | 39     | 0.014   |\n",
            "                                                            +-----------+----------+--------+---------+\u001b[0m\n",
            "\u001b[Ktotal_step   0%||  0/10 [00:00<?, 0.00/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:39 - 0:00:14 at base_trainer.py:87 - Found 41362 trainable parameters.\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 7.47/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:40 - 0:00:15 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  1_2                   |\n",
            "                                                            +-----------+---------+--------+---------+\n",
            "                                                            | name      | value   | weight | mean    |\n",
            "                                                            +-----------+---------+--------+---------+\n",
            "                                                            | grad_norm | 206.631 | 35     | 5.904   |\n",
            "                                                            | ll        | -534.95 | 35     | -15.284 |\n",
            "                                                            | reg       | 0.21    | 35     | 0.006   |\n",
            "                                                            +-----------+---------+--------+---------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.85/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:40 - 0:00:16 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  1_4                   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | name      | value    | weight | mean   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | grad_norm | 181.706  | 60     | 3.028  |\n",
            "                                                            | ll        | -369.481 | 60     | -6.158 |\n",
            "                                                            | reg       | 0.094    | 60     | 0.002  |\n",
            "                                                            +-----------+----------+--------+--------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 9.52/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:41 - 0:00:16 at base_trainer.py:137 - +---------------------------------------+\n",
            "                                                            |                  1_6                  |\n",
            "                                                            +-----------+---------+--------+--------+\n",
            "                                                            | name      | value   | weight | mean   |\n",
            "                                                            +-----------+---------+--------+--------+\n",
            "                                                            | grad_norm | 115.169 | 50     | 2.303  |\n",
            "                                                            | ll        | -418.24 | 50     | -8.365 |\n",
            "                                                            | reg       | 0.142   | 50     | 0.003  |\n",
            "                                                            +-----------+---------+--------+--------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 9.56/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:41 - 0:00:17 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  1_8                   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | name      | value    | weight | mean   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | grad_norm | 100.751  | 57     | 1.768  |\n",
            "                                                            | ll        | -362.732 | 57     | -6.364 |\n",
            "                                                            | reg       | 0.237    | 57     | 0.004  |\n",
            "                                                            +-----------+----------+--------+--------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.18/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:15:42 - 0:00:17 at base_trainer.py:137 - +-----------------------------------------+\n",
            "                                                            |                   1_10                  |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | name      | value    | weight | mean    |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | grad_norm | 114.494  | 32     | 3.578   |\n",
            "                                                            | ll        | -530.468 | 32     | -16.577 |\n",
            "                                                            | reg       | 0.304    | 32     | 0.01    |\n",
            "                                                            +-----------+----------+--------+---------+\u001b[0m\n",
            "\u001b[Keval_batch 100%|| 490/490 [00:24<00:00, 20.34/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:06 - 0:00:41 at base_trainer.py:154 - +------------------------------------------------------------+\n",
            "                                                            |                            Eval                            |\n",
            "                                                            +---------------------------+-------------+--------+---------+\n",
            "                                                            | name                      | value       | weight | mean    |\n",
            "                                                            +---------------------------+-------------+--------+---------+\n",
            "                                                            | ll                        | -158189.844 | 10740  | -14.729 |\n",
            "                                                            | prf_exact_span_f1         | 0.0         | N/A    | N/A     |\n",
            "                                                            | prf_exact_span_matches    | 0           | N/A    | N/A     |\n",
            "                                                            | prf_exact_span_precision  | 0.0         | N/A    | N/A     |\n",
            "                                                            | prf_exact_span_recall     | 0.0         | N/A    | N/A     |\n",
            "                                                            | prf_prefix_span_f1        | 0.0         | N/A    | N/A     |\n",
            "                                                            | prf_prefix_span_matches   | 0           | N/A    | N/A     |\n",
            "                                                            | prf_prefix_span_precision | 0.0         | N/A    | N/A     |\n",
            "                                                            | prf_prefix_span_recall    | 0.0         | N/A    | N/A     |\n",
            "                                                            | prf_total_correct         | 10740       | N/A    | N/A     |\n",
            "                                                            | prf_total_pred            | 0           | N/A    | N/A     |\n",
            "                                                            | reg                       | 80.079      | 10740  | 0.007   |\n",
            "                                                            +---------------------------+-------------+--------+---------+\u001b[0m\n",
            "\u001b[Ksave 100%|| 20/20 [00:31<00:00, 0.65/s]\u001b[1;1H\u001b[1;1H\u001b[36mIMP - 05/29/21 09:16:07 - 0:00:42 at logger.py:65 - Model saved to log/2021-05-29/default/09-15-25/saved.1_10.latest.\u001b[0m\n",
            "\u001b[33mWARNING - 05/29/21 09:16:07 - 0:00:42 at trainer.py:223 - Do NOT use this number since this f1 is compared against ground truths.\u001b[0m\n",
            "\u001b[36mIMP - 05/29/21 09:16:07 - 0:00:42 at logger.py:65 - Best model updated: new best is 0.000\u001b[0m\n",
            "\u001b[36mIMP - 05/29/21 09:16:08 - 0:00:43 at logger.py:65 - Model saved to log/2021-05-29/default/09-15-25/saved.1_10.best.\u001b[0m\n",
            "\u001b[Ktotal_step   0%||  0/10 [00:00<?, 0.00/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:08 - 0:00:43 at base_trainer.py:87 - Found 41362 trainable parameters.\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 9.49/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:09 - 0:00:44 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  2_2                   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | name      | value    | weight | mean   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | grad_norm | 79.068   | 53     | 1.492  |\n",
            "                                                            | ll        | -382.549 | 53     | -7.218 |\n",
            "                                                            | reg       | 0.336    | 53     | 0.006  |\n",
            "                                                            +-----------+----------+--------+--------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 8.53/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:09 - 0:00:44 at base_trainer.py:137 - +-----------------------------------------+\n",
            "                                                            |                   2_4                   |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | name      | value    | weight | mean    |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | grad_norm | 84.78    | 43     | 1.972   |\n",
            "                                                            | ll        | -439.248 | 43     | -10.215 |\n",
            "                                                            | reg       | 0.315    | 43     | 0.007   |\n",
            "                                                            +-----------+----------+--------+---------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.84/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:10 - 0:00:45 at base_trainer.py:137 - +---------------------------------------+\n",
            "                                                            |                  2_6                  |\n",
            "                                                            +-----------+----------+--------+-------+\n",
            "                                                            | name      | value    | weight | mean  |\n",
            "                                                            +-----------+----------+--------+-------+\n",
            "                                                            | grad_norm | 74.828   | 43     | 1.74  |\n",
            "                                                            | ll        | -429.563 | 43     | -9.99 |\n",
            "                                                            | reg       | 0.267    | 43     | 0.006 |\n",
            "                                                            +-----------+----------+--------+-------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 10.93/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:10 - 0:00:45 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  2_8                   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | name      | value    | weight | mean   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | grad_norm | 57.104   | 67     | 0.852  |\n",
            "                                                            | ll        | -289.878 | 67     | -4.327 |\n",
            "                                                            | reg       | 0.279    | 67     | 0.004  |\n",
            "                                                            +-----------+----------+--------+--------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.83/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:11 - 0:00:46 at base_trainer.py:137 - +-----------------------------------------+\n",
            "                                                            |                   2_10                  |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | name      | value    | weight | mean    |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | grad_norm | 73.564   | 39     | 1.886   |\n",
            "                                                            | ll        | -453.823 | 39     | -11.636 |\n",
            "                                                            | reg       | 0.357    | 39     | 0.009   |\n",
            "                                                            +-----------+----------+--------+---------+\u001b[0m\n",
            "\u001b[Ktotal_step   0%||  0/10 [00:00<?, 0.00/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:11 - 0:00:46 at base_trainer.py:87 - Found 41362 trainable parameters.\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.88/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:11 - 0:00:47 at base_trainer.py:137 - +-----------------------------------------+\n",
            "                                                            |                   3_2                   |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | name      | value    | weight | mean    |\n",
            "                                                            +-----------+----------+--------+---------+\n",
            "                                                            | grad_norm | 80.889   | 36     | 2.247   |\n",
            "                                                            | ll        | -464.064 | 36     | -12.891 |\n",
            "                                                            | reg       | 0.423    | 36     | 0.012   |\n",
            "                                                            +-----------+----------+--------+---------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.86/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:12 - 0:00:47 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  3_4                   |\n",
            "                                                            +-----------+---------+--------+---------+\n",
            "                                                            | name      | value   | weight | mean    |\n",
            "                                                            +-----------+---------+--------+---------+\n",
            "                                                            | grad_norm | 72.328  | 34     | 2.127   |\n",
            "                                                            | ll        | -492.62 | 34     | -14.489 |\n",
            "                                                            | reg       | 0.459   | 34     | 0.013   |\n",
            "                                                            +-----------+---------+--------+---------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 8.34/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:12 - 0:00:48 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  3_6                   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | name      | value    | weight | mean   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | grad_norm | 63.204   | 46     | 1.374  |\n",
            "                                                            | ll        | -400.835 | 46     | -8.714 |\n",
            "                                                            | reg       | 0.5      | 46     | 0.011  |\n",
            "                                                            +-----------+----------+--------+--------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.83/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:13 - 0:00:48 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  3_8                   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | name      | value    | weight | mean   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | grad_norm | 58.492   | 60     | 0.975  |\n",
            "                                                            | ll        | -336.246 | 60     | -5.604 |\n",
            "                                                            | reg       | 0.555    | 60     | 0.009  |\n",
            "                                                            +-----------+----------+--------+--------+\u001b[0m\n",
            "\u001b[Kcheck 100%|| 2/2 [00:00<00:00, 6.17/s]\u001b[1;1H\u001b[1;1H\u001b[32mINFO - 05/29/21 09:16:13 - 0:00:49 at base_trainer.py:137 - +----------------------------------------+\n",
            "                                                            |                  3_10                  |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | name      | value    | weight | mean   |\n",
            "                                                            +-----------+----------+--------+--------+\n",
            "                                                            | grad_norm | 61.166   | 48     | 1.274  |\n",
            "                                                            | ll        | -405.898 | 48     | -8.456 |\n",
            "                                                            | reg       | 0.631    | 48     | 0.013  |\n",
            "                                                            +-----------+----------+--------+--------+\u001b[0m\n",
            "\u001b[Keval_batch   6%||  31/490 [00:02<00:23, 20.27/s]\u001b[1;1H\u001b[1;1HTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 557, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/xib/xib/data_loader.py\", line 324, in __getitem__\n",
            "    ret = super().__getitem__(idx)\n",
            "  File \"/content/xib/xib/data_loader.py\", line 238, in __getitem__\n",
            "    ret['gold_tag_seq'] = ret['segment'].gold_tag_seq\n",
            "  File \"/content/xib/xib/ipa/process.py\", line 392, in gold_tag_seq\n",
            "    return torch.cat([segment.gold_tag_seq for segment in self._segments], dim=0)\n",
            "  File \"/content/xib/dev_misc/dev_misc/devlib/named_tensor.py\", line 417, in cat\n",
            "    return call_unpatched(tensors, dim=dim, out=out)\n",
            "  File \"/content/xib/dev_misc/dev_misc/devlib/named_tensor.py\", line 96, in call_unpatched\n",
            "    return unpatched(*args, **kwargs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/xib/xib/main.py\", line 51, in <module>\n",
            "    train()\n",
            "  File \"/content/xib/xib/main.py\", line 38, in train\n",
            "    manager.run()\n",
            "  File \"/content/xib/xib/training/manager.py\", line 266, in run\n",
            "    self.trainer.train(self.dl_reg)\n",
            "  File \"/content/xib/dev_misc/dev_misc/trainlib/base_trainer.py\", line 104, in train\n",
            "    eval_metrics = self.try_evaluate()\n",
            "  File \"/content/xib/dev_misc/dev_misc/trainlib/base_trainer.py\", line 150, in try_evaluate\n",
            "    return self.evaluate()\n",
            "  File \"/content/xib/dev_misc/dev_misc/trainlib/base_trainer.py\", line 153, in evaluate\n",
            "    eval_metrics = self.evaluator.evaluate(self.stage)\n",
            "  File \"/content/xib/xib/training/evaluator.py\", line 264, in evaluate\n",
            "    for batch in pbar(self.dl, desc=\"eval_batch\"):\n",
            "  File \"/content/xib/dev_misc/dev_misc/utils.py\", line 70, in pbar\n",
            "    for item in iterator:\n",
            "  File \"/content/xib/xib/data_loader.py\", line 412, in __iter__\n",
            "    for batch in super().__iter__():\n",
            "  File \"/content/xib/xib/data_loader.py\", line 174, in __iter__\n",
            "    for collate_return in super().__iter__():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
            "    return data\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/profiler.py\", line 621, in __exit__\n",
            "    torch.ops.profiler._record_function_exit(self.handle)\n",
            "KeyboardInterrupt\n",
            "\u001b[1;0r\u001b[1;1H\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aS6jXpiZ7Ua"
      },
      "source": [
        "# Analyzing The Result\n",
        "\n",
        "The result will be in the following file `log/<DATE>/default/<TIME>/predictions/extract.<EPOCH>_<STEPS>.tsv`\n",
        "\n",
        "For some reason, google colab won't show anything under `log` folder, so I would suggest to analyze it via `cat` command or download the result to your local computer and analyze it from there.\n",
        "\n",
        "The content inside of the `tsv` file will consist of 4 different columns: `segment`, `ground_truth`, `prediction`, `matched_segment`. From my understanding, `segment` is the original segment of the unknown language; `ground_truth` similar to `segment` but with their exact index locations; `prediction` is the vocabulary prediction in the known language; and `matched_segment` is the information on which segment the unknown language match the vocabulary in known language. If you want, you can get more details by looking at the code in `evaluator.py` line 257\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubz4eYmdf7MM"
      },
      "source": [
        "# You can run the following command **sequentially**\n",
        "# !ls log/ # to get the list of experiment dates\n",
        "# !ls log/<date>/default/ # to get the list of experiment times, first replace date from the command above\n",
        "# !ls log/<date>/default/<time>/predictions/<filename> # to get the list of filename, first replace date and time from the commands above\n",
        "\n",
        "# Replace <date>, <time>, and <filename> from the commands above\n",
        "# !cat log/<date>/default/<time>/predictions/<filename>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPuUbwNwdZ0Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1aea28a0-590c-463a-aba7-b3fdbdcced37"
      },
      "source": [
        "# Or you can run the following command to download the result to your local environment\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"log/2021-05-29/default/09-15-25/predictions/extract.1_10.tsv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1c071154-88f2-493b-90dc-afb1adb3ce53\", \"extract.1_10.tsv\", 314792)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4kdXzy2aFZP"
      },
      "source": [
        "The other way around is to direct the output to your google drive folder by setting up `--log_dir` parameter on the script. However, by setting up this parameter we won't have the same directory structure format as if we don't set the parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEOIhpbdd2DG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}